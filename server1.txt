# server.py - Fixed version with proper global browser and queue system
import os
import uvicorn
import asyncio
import scraper
import logging
from datetime import datetime, timedelta, timezone
from pathlib import Path
from typing import Optional
from contextlib import asynccontextmanager

from fastapi import FastAPI, Query, HTTPException, Form
# server.py - Fix imports at the top
from datetime import datetime, timedelta, timezone
from fastapi.middleware.cors import CORSMiddleware
from playwright.async_api import async_playwright
from auto_scraper import auto_scraper, check_episode_servers
from fastapi.responses import HTMLResponse, JSONResponse
from fastapi.staticfiles import StaticFiles

from db import (
    episodes_collection,
    cache_collection,  # Make sure this line is present
    add_episode, get_episode,
    get_cached, set_cached
)
from scraper import scrape_vcloud

logger = logging.getLogger("server")
logging.basicConfig(level=logging.INFO)

# Global Playwright/browser references
_global_playwright = None
_global_browser = None


@asynccontextmanager
async def lifespan(app: FastAPI):
    """FIXED: Proper lifespan with global browser setup"""
    global _global_playwright, _global_browser
    
    # STARTUP
    logger.info("Starting Playwright and background tasks...")

    try:
        _global_playwright = await async_playwright().start()
        _global_browser = await _global_playwright.chromium.launch(
            headless=True,
            args=[
                "--no-sandbox",
                "--disable-setuid-sandbox",
                "--disable-dev-shm-usage",
                "--disable-gpu",
                "--single-process",
                "--disable-background-timer-throttling",
                "--disable-backgrounding-occluded-windows",
                "--disable-renderer-backgrounding",
            ]
        )
        
        # Register global browser in scraper.py
        scraper.set_browser(_global_playwright, _global_browser)
        logger.info("√¢≈ì‚Ä¶ Global Playwright/browser registered successfully")
        
    except Exception as e:
        logger.exception(f"Failed to start global Playwright/browser: {e}")

    # Initialize app state
    app.state.scrape_lock = asyncio.Lock()
    app.state.scrape_queue = asyncio.Queue()
    app.state.queued_episodes = set()

    # Start ALL background tasks
    task_auto = asyncio.create_task(auto_scraper.run_auto_scraper())
    queue_task = asyncio.create_task(_queue_worker(app))
    heartbeat_task = asyncio.create_task(_browser_heartbeat())  # √¢‚Ä†¬ê FIX: START HEARTBEAT

    yield  # Application running

    # SHUTDOWN
    logger.info("Shutting down background tasks and Playwright...")
    auto_scraper.stop()
    
    # Cancel ALL background tasks
    task_auto.cancel()
    queue_task.cancel()
    heartbeat_task.cancel()  # √¢‚Ä†¬ê FIX: STOP HEARTBEAT
    
    # Wait for all tasks to finish cancelling
    await asyncio.gather(task_auto, queue_task, heartbeat_task, return_exceptions=True)

    try:
        if _global_browser:
            await _global_browser.close()
        if _global_playwright:
            await _global_playwright.stop()
    except Exception as e:
        logger.warning(f"Error closing Playwright/browser: {e}")

    # Unset in scraper
    scraper.set_browser(None, None)

# ADD THIS NEW FUNCTION RIGHT AFTER THE LIFESPAN FUNCTION
async def _browser_heartbeat():
    """Background task to keep browser alive proactively"""
    while True:
        await asyncio.sleep(180)  # Check every 3 minutes
        try:
            # Get current browser (this will do health check if needed)
            browser = await scraper.get_browser()
            if browser:
                # Quick health verification - open and close a context
                context = await browser.new_context()
                await context.close()
                logger.debug("√¢≈ì‚Ä¶ Browser heartbeat check passed")
            else:
                logger.warning("üí¢ Browser heartbeat: no browser available")
        except Exception as e:
            logger.warning(f"√¢≈° √Ø¬∏¬è Browser heartbeat failed: {e}")
            # Don't panic - the next scrape will trigger browser restart


# Initialize FastAPI with lifespan
app = FastAPI(lifespan=lifespan)

# Mount static files
app.mount("/static", StaticFiles(directory="."), name="static")

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


async def _queue_worker(app):
    """
    Queue worker that processes scrapes one by one - PER EPISODE cooldown
    """
    q = app.state.scrape_queue
    queued_set = app.state.queued_episodes
    
    while True:
        ep_id = None
        try:
            ep_id, show, ep = await q.get()
            logger.info(f"‚≠ï Queue worker: processing {ep_id}")
            
            # Remove from queued set now that we're processing
            queued_set.discard(ep_id)
            
            # Check if cache already exists and is fresh (PER EPISODE)
            cached = await get_cached(ep_id)
            if cached:
                cache_doc = await cache_collection.find_one({"_id": ep_id})
                if cache_doc:
                    expire_at = cache_doc.get("expireAt")
                    current_time = datetime.now(timezone.utc)  # FIXED
                    if expire_at and expire_at > current_time:
                        time_remaining = (expire_at - current_time).total_seconds() / 60
                        if time_remaining > 10:  # More than 10 minutes remaining
                            logger.info(f"‚è≠Ô∏è  Skipping {ep_id} - cache is still fresh ({time_remaining:.1f} minutes remaining)")
                            continue
            
            # Use lock to ensure only one scrape runs at a time
            async with app.state.scrape_lock:
                doc = await get_episode(ep_id)
                if not doc:
                    logger.warning(f"Episode missing in queue_worker: {ep_id}")
                    continue
                
                master = doc.get("master", {})
                scraped = {}
                
                for quality, url in master.items():
                    try:
                        logger.info(f"‚≠ï Scraping {quality}p from {url}")
                        res = await scrape_vcloud(url)
                        scraped[quality] = res or {}
                        logger.info(f"‚úÖ {quality}p -> {len(scraped[quality])} servers")
                    except Exception as e:
                        logger.error(f"‚ùå {quality}p error: {e}")
                        scraped[quality] = {}
                
                # Increase cache TTL to 6 hours (21600 seconds)
                await set_cached(ep_id, scraped, ttl=21600)
                logger.info(f"‚úÖ Queue worker: cached results for {ep_id}")
                
        except Exception as e:
            logger.exception(f"Queue worker loop error: {e}")
        finally:
            if ep_id:
                queued_set.discard(ep_id)  # Ensure it's removed even on error
            q.task_done()


# ------------------- Routes -------------------

@app.get("/")
async def root():
    return {"status": "ok", "msg": "WebPlayer running"}


@app.get("/player", response_class=HTMLResponse)
async def player_page(show: str = Query(...), ep: int = Query(...)):
    """Serve the player HTML"""
    html_content = '''<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>KDRAMA Player</title>
  <style>
    body { margin:0; font-family:Arial, sans-serif; background:#111; color:#fff; }
    .topbar { display:flex; justify-content:space-between; align-items:center;
      padding:12px; background:#000; }
    .branding { display:flex; align-items:center; gap:8px; }
    .branding span { background:#2a9df4; padding:6px 10px; border-radius:4px; font-weight:bold; }
    .channel { font-size:18px; font-weight:bold; }
    .btn { background:#222; padding:6px 10px; margin-left:6px; border:1px solid #333;
           border-radius:4px; cursor:pointer; color:#fff; text-decoration:none; display:inline-block; }
    .btn:hover { background:#333; }
    .video-container { max-width:950px; margin:20px auto; }
    .servers, .downloads { max-width:950px; margin:10px auto; }
    .servers button, .downloads button, .downloads a {
      margin:5px; padding:6px 12px; border-radius:6px; background:#333; color:#fff;
      border:none; cursor:pointer; text-decoration:none; display:inline-block;
    }
    .servers button:hover, .downloads button:hover, .downloads a:hover { background:#444; }
    .servers button.active { background:#2a9df4; }
    .downloads a { background:#2d5a2d; }
    .downloads a:hover { background:#3d6a3d; }
    .error { color:#f66; margin-top:6px; }
    .status { color:#4a9; margin:10px; }
    .server-count { color:#4a9; font-size:14px; margin:5px 0; }
    .warning { color:#ff9500; margin:10px; padding:8px; background:#2a1f0a; border-radius:4px; }
    #videoPlayer { width: 100%; height: 500px; }
  </style>
  <link href="https://vjs.zencdn.net/7.21.1/video-js.css" rel="stylesheet">
</head>
<body>
  <div class="topbar">
    <div class="branding">
      <span>ü§óü§óüôÇ</span>
      <div class="channel">KDRAMA Player</div>
    </div>
    <div class="utils">
      <button class="btn" onclick="openDirect()">Open Direct</button>
      <button class="btn" onclick="openVLC()">Play in VLC</button>
      <button class="btn" onclick="forceScrap()">Force Scrape</button>
      <button class="btn" onclick="refreshPage()">Refresh</button>
    </div>
  </div>

  <div class="video-container">
    <video id="videoPlayer" class="video-js vjs-default-skin" controls preload="auto" width="950" height="500"></video>
  </div>

  <div class="servers">
    <h3>Servers</h3>
    <div id="server-count" class="server-count"></div>
    <div id="servers"></div>
    <div id="status" class="status"></div>
    <div id="warning" class="warning" style="display:none;"></div>
  </div>

  <div class="downloads">
    <h3>Download</h3>
    <div id="downloads"></div>
  </div>

  <script src="https://vjs.zencdn.net/7.21.1/video.min.js"></script>
  <script>
    let currentLink = null;
    let player = null;

    async function loadEpisode() {
      try {
        const params = new URLSearchParams(window.location.search);
        const show = params.get("show");
        const ep = params.get("ep");

        if (!show || !ep) {
          document.getElementById("servers").innerText = "üí¶ Missing show/ep params";
          return;
        }

        document.getElementById("status").innerText = "Loading episode data...";

        const res = await fetch(`/get_link?show=${encodeURIComponent(show)}&ep=${encodeURIComponent(ep)}`);
        if (!res.ok) {
          throw new Error(`HTTP ${res.status}: ${res.statusText}`);
        }
        
        let data = await res.json();
        console.log("Episode data:", data);

        const serversDiv = document.getElementById("servers");
        const downloadsDiv = document.getElementById("downloads");
        const statusDiv = document.getElementById("status");
        const serverCountDiv = document.getElementById("server-count");
        const warningDiv = document.getElementById("warning");
        
        serversDiv.innerHTML = "";
        downloadsDiv.innerHTML = "";
        warningDiv.style.display = "none";

        if (data.server_info) {
            serverCountDiv.innerText = `Servers: ${data.server_info.server_count}/9`;
            
            if (data.server_info.needs_force_scrape) {
                warningDiv.innerText = data.server_info.message;
                warningDiv.style.display = "block";
            }
        }

        if (!player) {
          player = videojs("videoPlayer", {
            fluid: true,
            responsive: true,
            playbackRates: [0.5, 1, 1.25, 1.5, 2]
          });
        }

        let links = {};
        if (data.status === "cached" && data.links) {
          links = data.links;
          statusDiv.innerText = "√¢≈ì‚Ä¶ Cached links loaded";
        } else if (data.status === "master" && data.links) {
          statusDiv.innerText = "√¢≈° √Ø¬∏¬è Only master links found. Click 'Force Scrape' to get direct links.";
          for (const [quality, masterUrl] of Object.entries(data.links)) {
            const btn = document.createElement("button");
            btn.innerText = `${quality}p (Master)`;
            btn.onclick = () => {
              currentLink = masterUrl;
              player.src({ src: masterUrl, type: "video/mp4" });
              player.ready(() => player.play());
            };
            serversDiv.appendChild(btn);
          }
          return;
        } else {
          statusDiv.innerText = "üí¢ No links found";
          return;
        }

        let hasAnyServers = false;

        for (const [quality, servers] of Object.entries(links)) {
          if (!servers || typeof servers !== 'object') continue;

          for (const [serverName, link] of Object.entries(servers)) {
            if (!link) continue;
            
            hasAnyServers = true;
            const btn = document.createElement("button");
            btn.innerText = `${quality}p (${serverName})`;
            btn.onclick = () => {
              document.querySelectorAll('.servers button').forEach(b => b.classList.remove('active'));
              btn.classList.add('active');
              currentLink = link;
              player.src({ src: link, type: "video/mp4" });
              player.ready(() => player.play().catch(e => {
                console.error("Play error:", e);
                statusDiv.innerText = "üí¢ Failed to play. Try another server.";
              }));
            };
            serversDiv.appendChild(btn);
          }

          for (const [serverName, link] of Object.entries(servers)) {
            if (!link) continue;
            const a = document.createElement("a");
            a.href = link;
            a.innerText = `${quality}p (${serverName})`;
            a.className = "btn";
            a.setAttribute("download", "");
            a.target = "_blank";
            downloadsDiv.appendChild(a);
          }
        }

        if (hasAnyServers) {
          const qualityOrder = ["1080", "720", "480"];
          for (const q of qualityOrder) {
            if (links[q] && Object.keys(links[q]).length > 0) {
              const firstServer = Object.values(links[q])[0];
              if (firstServer) {
                currentLink = firstServer;
                player.src({ src: firstServer, type: "video/mp4" });
                const firstBtn = serversDiv.querySelector('button');
                if (firstBtn) firstBtn.classList.add('active');
                statusDiv.innerText = `√¢≈ì‚Ä¶ Ready to play ${q}p`;
                break;
              }
            }
          }
        } else {
          statusDiv.innerText = "üí¢ No playable servers found";
        }

      } catch (err) {
        console.error("Load error:", err);
        document.getElementById("status").innerHTML = `üí¢ Error: ${err.message}`;
      }
    }

    function openDirect() {
      if (currentLink) window.open(currentLink, "_blank");
      else alert("No video selected");
    }

    function openVLC() {
      if (currentLink) window.location.href = "vlc://" + currentLink;
      else alert("No video selected");
    }

    // In the forceScrap() function - this should already work correctly
    async function forceScrap() {
      const params = new URLSearchParams(window.location.search);
      const show = params.get("show");
      const ep = params.get("ep");

      if (!show || !ep) {
        alert("Missing show/ep parameters");
        return;
      }

      document.getElementById("status").innerText = "üîÑ Scraping...";

      try {
        const res = await fetch(`/scrape?show=${encodeURIComponent(show)}&ep=${encodeURIComponent(ep)}`);
        const data = await res.json();

        if (data.status === "queued") {
          document.getElementById("status").innerText = "‚è≥ Scraping queued, please wait 30 seconds then refresh...";
          setTimeout(() => loadEpisode(), 30000);
        } else if (data.status === "cooldown") {
          document.getElementById("status").innerText = "‚è≥ " + data.message;
          // Auto-refresh when cooldown is over (check every minute)
          const waitTime = 60000;
          setTimeout(() => loadEpisode(), waitTime);
        } else if (data.status === "already_queued") {
          document.getElementById("status").innerText = "‚è≥ " + data.message;
        } else {
          document.getElementById("status").innerText = "‚ùå Scraping failed";
          alert("Scraping failed: " + (data.message || "Unknown error"));
        }
      } catch (err) {
        console.error("Scrape error:", err);
        document.getElementById("status").innerText = "‚ùå Scraping error";
        alert("Scraping error: " + err.message);
      }
    }

    function refreshPage() {
      window.location.reload();
    }

    window.addEventListener('DOMContentLoaded', loadEpisode);
  </script>
</body>
</html>'''
    return HTMLResponse(html_content)


@app.get("/admin", response_class=HTMLResponse)
async def admin_page():
    """Admin UI page"""
    html = """
    <html>
    <head>
        <title>Admin Panel</title>
        <style>
            body { font-family: Arial; margin: 24px; background: #f7f7f7; }
            input, button { margin: 5px; padding: 8px; }
            .section { background: white; padding: 16px; margin: 16px 0; border-radius: 8px; }
            .result { margin-top: 10px; padding: 10px; background: #eef; white-space: pre-wrap; }
        </style>
    </head>
    <body>
        <h1>‚ò¢ Admin Panel</h1>

        <div class="section">
            <h2>Add Episode</h2>
            <form id="addForm">
                Show: <input name="show" required><br>
                Episode: <input name="ep" type="number" required><br>
                480p: <input name="link480"><br>
                720p: <input name="link720"><br>
                1080p: <input name="link1080"><br>
                <button type="submit">Add</button>
            </form>
            <div id="addResult" class="result"></div>
        </div>

        <div class="section">
            <h2>Remove Episode</h2>
            <form id="removeForm">
                Show: <input name="show" required><br>
                Episode: <input name="ep" type="number" required><br>
                <button type="submit">Remove</button>
            </form>
            <div id="removeResult" class="result"></div>
        </div>

        <div class="section">
            <h2>Search</h2>
            <form id="searchForm">
                Show: <input name="show" required><br>
                <button type="submit">Search</button>
            </form>
            <div id="searchResult" class="result"></div>
        </div>

        <script>
        document.getElementById('addForm').onsubmit = async (e) => {
            e.preventDefault();
            let fd = new FormData(e.target);
            let res = await fetch('/admin/add_episode', {method:'POST', body:fd});
            let data = await res.json();
            if(data.status === 'ok'){
                document.getElementById('addResult').innerHTML =
                  "ü§ç‚Ä¶ Added<br>Player: <a href='" + data.player_link + "' target='_blank'>" + data.player_link + "</a>";
            } else {
                document.getElementById('addResult').innerText = JSON.stringify(data, null, 2);
            }
        };
        document.getElementById('removeForm').onsubmit = async (e) => {
            e.preventDefault();
            let fd = new FormData(e.target);
            let res = await fetch('/admin/remove_episode', {method:'POST', body:fd});
            let data = await res.json();
            document.getElementById('removeResult').innerText = JSON.stringify(data, null, 2);
        };
        document.getElementById('searchForm').onsubmit = async (e) => {
            e.preventDefault();
            let fd = new FormData(e.target);
            let res = await fetch('/admin/search_episode?show='+fd.get('show'));
            let data = await res.json();
            document.getElementById('searchResult').innerText = JSON.stringify(data, null, 2);
        };
        </script>
    </body>
    </html>
    """
    return HTMLResponse(html)


@app.get("/scrape")
async def scrape_handler(show: str = Query(...), ep: int = Query(...)):
    """Queue-based scraping with PER-EPISODE 10-minute cooldown"""
    ep_id = f"{show}:{ep}"
    doc = await get_episode(ep_id)
    if not doc:
        raise HTTPException(status_code=404, detail="Episode not found")

    # Check cache freshness - enforce 10-minute cooldown PER EPISODE
    cached = await get_cached(ep_id)
    if cached:
        cache_doc = await cache_collection.find_one({"_id": ep_id})
        if cache_doc:
            expire_at = cache_doc.get("expireAt")
            current_time = datetime.now(timezone.utc)  # FIXED: Use timezone-aware UTC
            if expire_at and expire_at > current_time:
                time_remaining = (expire_at - current_time).total_seconds() / 60
                if time_remaining > 10:  # More than 10 minutes remaining
                    return {
                        "status": "cooldown", 
                        "message": f"Cache is still fresh for this episode. Please wait {time_remaining:.1f} minutes before scraping again."
                    }

    # Check if already queued (PER EPISODE)
    if ep_id in app.state.queued_episodes:
        return {"status": "already_queued", "message": f"This episode is already in the scrape queue"}

    # Add to queue and track it (PER EPISODE)
    app.state.queued_episodes.add(ep_id)
    await app.state.scrape_queue.put((ep_id, show, ep))
    
    logger.info(f"‚úÖ Scrape queued for {ep_id} - other episodes can still be scraped")
    return {"status": "queued", "message": "Scrape queued; will run shortly"}


@app.get("/get_link")
async def get_link(show: str = Query(...), ep: int = Query(...)):
    """Get episode links (cached or master)"""
    ep_id = f"{show}:{ep}"
    
    server_info = await check_episode_servers(ep_id)
    
    cached = await get_cached(ep_id)
    if cached:
        return {
            "status": "cached", 
            "links": cached,
            "server_info": server_info
        }

    doc = await get_episode(ep_id)
    if not doc:
        raise HTTPException(status_code=404, detail="Episode not found")
    
    return {
        "status": "master", 
        "links": doc.get("master", {}),
        "server_info": server_info
    }


@app.post("/admin/add_episode")
async def admin_add_episode(
    show: str = Form(...), ep: int = Form(...),
    link480: Optional[str] = Form(None),
    link720: Optional[str] = Form(None),
    link1080: Optional[str] = Form(None),
):
    ep_id = f"{show}:{ep}"
    master = {}
    if link480: master["480"] = link480.strip()
    if link720: master["720"] = link720.strip()
    if link1080: master["1080"] = link1080.strip()

    if not master:
        return JSONResponse({"status":"error","msg":"Need at least one link"}, status_code=400)

    await add_episode(ep_id, master)
    return {"status":"ok","episode":ep_id,"player_link":f"/player?show={show}&ep={ep}"}


@app.post("/admin/remove_episode")
async def admin_remove_episode(show: str = Form(...), ep: int = Form(...)):
    ep_id = f"{show}:{ep}"
    res = await episodes_collection.delete_one({"_id": ep_id})
    return {"status": "ok" if res.deleted_count else "not_found", "episode": ep_id}


@app.get("/admin/search_episode")
async def admin_search_episode(show: str):
    cursor = episodes_collection.find({"_id":{"$regex":f"^{show}:"}})
    docs = await cursor.to_list(1000)
    return {"count":len(docs),"episodes":docs}


@app.get("/debug/episode")
async def debug_episode(show: str = Query(...), ep: int = Query(...)):
    """Debug endpoint to check episode status"""
    ep_id = f"{show}:{ep}"
    doc = await get_episode(ep_id)
    cached = await get_cached(ep_id)
    return {
        "episode": ep_id,
        "master": doc.get("master") if doc else None,
        "cached": cached,
    }


if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=int(os.getenv("PORT", "8000")))